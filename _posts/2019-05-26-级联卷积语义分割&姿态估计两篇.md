---
layout:     post
title:      自级联卷积网络遥感语义分割阅读笔记
subtitle:   Semantic Labeling in Very High Resolution Images via A Self-Cascaded Convolutional Neural Network & Cascaded Pyramid Network for Multi-Person Pose Estimation
date:       2019-05-27
author:     Nick
header-img: img/博客背景.jpg
catalog: true
tags:
    - 语义分割
    - 论文阅读
---

## 摘要

城市超高分辨率(VHR)图像的语义标注在遥感的广泛应用中具有重要意义。然而，许多令人困惑的人造物体和错综复杂的精细结构物体使其很难获得一致和准确的标记结果。针对这一具有挑战性的任务，我们提出了一种新的卷积神经网络(CNNs)深度模型。，一个端到端自级联网络(ScasNet)。特别地，对于容易混淆的人工对象，ScasNet通过连续的全局到本地上下文聚合提高了标记的一致性。从技术上讲，在**CNN编码器的输出中捕获多尺度上下文，然后以自级联的方式依次聚合它们**。同时，**对于精细结构的对象，ScasNet采用由粗到精的细化策略**，提高了标签的精度。它利用CNN浅层学习到的低层特征逐步细化目标对象。此外，**针对ScasNet内部多特征融合引起的潜在拟合残差，提出了一种专用的残差校正方案**。它大大提高了ScasNet的有效性。在三个公共数据集上的大量实验结果(包括两个具有挑战性的基准测试)表明，ScasNet实现了最先进的性能。

## 1. 简介

超高分辨率图像的语义标注是遥感领域的一个长期研究课题。它在基础设施规划、国土规划和城市变化检测等许多重要应用中发挥着至关重要的作用。这个问题的目标是将每个像素分配给一个给定的对象类别。需要注意的是，不仅仅是建筑提取、道路提取和植被提取，只考虑一个类别的标注，语义标注通常同时考虑多个类别。因此，这项任务是非常具有挑战性的，特别是在城市地区，显示出高度的多样性的人造物体。具体来说，一方面，许多人造物体(如建筑物)显示出不同的结构，它们由大量不同的材料组成。同时，许多不同的人造物体(如建筑物和道路)呈现出非常相似的视觉特征。这些令人困惑的人工对象具有**较高的类内方差和较低的类间方差**，给一致性标注带来了很大的困难。另一方面，**城市中的精细结构（如车、低植被、树）都相当小或者呈细长状，并且他们之间通过遮挡和阴影相互影响**。这些因素往往导致不准确的标记结果。此外，它提出了额外的挑战，同时标记所有这些大小各异的对象。

要完成这样一个具有挑战性的任务，需要不同级别的特征。具体来说，**抽象的高层特征更适合于识别容易混淆的人工对象，而精细结构对象的标注则可以从详细的低层特征中获益**。卷积神经网络在深度学习领域以特征学习著称。CNNs由多个可训练层组成，可以提取不同层次的表达特征。此外，近年来，深度学习的CNNs在计算机视觉领域表现出了显著的学习能力，如场景识别和图像分割。同时，许多基于cnns的方法也极大地促进了遥感的发展。例如，Lu et al. 研究了反卷积网络用于遥感场景分类，Chen et al. 利用CNNs对SAR图像进行目标分类。

基于CNNs，提出了许多**patch-classification**方法来进行语义标注。这些方法通过使用CNNs对目标像素周围的小块区域进行分类来确定像素标签。然而，它们远远不是最优的，因为它们忽略了补丁与时间消耗之间的内在关系。通常，**全卷积网络(FCNs)**大大提高了语义标注的准确性。FCNs直接进行像素级分类，现已成为语义标注的常用框架。**然而，由于FCNs中存在多次下采样，最终的特征图比输入图像糊得多，导致标记结果不准确。**

因此，如何在基于fcn的方法粗糙输出的情况下，对VHR图像中的精细结构对象进行准确的标记是一个难题。为了解决这个问题，一些研究尝试重用CNNs浅层学习到的低层特征。其目的是利用特征图捕捉到的局部细节(例如，角和边)获得高分辨率。在技术上，它们执行多级特征融合操作。这些方法大多**采用直接叠加融合策略。但是，这种策略忽略了不同层次特性中固有的语义差异**。另一种方法是强制进行边界检测。它通常需要额外的边界监督，虽然提高了目标定位的准确性，但也会导致模型的额外复杂性。

另一个棘手的问题是混淆对象的标记不一致，尤其是VHR图像中的各种人造对象。为了解决这一问题，一些研究集中于利用多上下文信息来提高这些对象的识别能力。他们使用多尺度图像或多区域图像作为CNNs的输入。然而，由于大量的重复计算，这些方法通常效率较低。不同的是，其他一些研究致力于从CNNs内部获取多上下文信息。它们通常执行多尺度扩张卷积、多尺度池化或多尺度卷积核，然后**将获得的多尺度上下文直接叠加融合。然而，这种方式不仅忽略了对象和场景在不同尺度上的层次依赖关系，而且忽略了不同层次信息上下文中固有的语义鸿沟。**

总之，虽然目前基于CNN的方法在语义标注方面取得了重大突破，但在城市地区标记VHR图像仍然很困难。原因如下：**1）大多数现有方法不能有效地获得混淆人造物体识别的多尺度背景; 2）大多数现有策略在利用低级特征进行精确标记方面效果较差，特别是对于结构化的对象; 3）由于网络中存在大量的残差，这是由于不同级别的上下文和特征中的语义差距造成的，因此用单个网络同时解决上述两个问题尤其困难。**

在本文中，我们提出了一种新颖的自级联卷积神经网络（ScasNet），如下图所示。这项工作的目的是进一步推进VHR图像中语义标记的最新技术。为此，它集中在三个方面：**1）多尺度上下文聚合，用于区分混淆的人造对象; 2）利用低级特征来完成结构化对象的改进; 3）残差校正，以实现更有效的多特征融合**。具体而言，采用传统的CNN作为编码器来提取不同级别的特征。在由编码器输出的特征图上，顺序地聚合全局到局部上下文以用于混淆人造对象识别。从技术上讲，**多尺度上下文首先由不同的卷积运算捕获，然后它们以自级联方式连续聚合**。利用获得的上下文信息，**执行粗略到精简的策略以重新定义结构化的对象**。它逐步重新利用CNN浅层与大跨度连接所学习的低级特征。另外，**为了校正由多特征融合中的语义间隙引起的潜在残留残差，在整个网络中采用了几种残差校正方案**。作为残差校正的结果，当上述两种不同的解决方案集成到单个网络中时，它们可以协同有效地工作。大量实验证明了ScasNet的有效性。此外，ScasNet中的三个子模块不仅可以为语义标记提供良好的解决方案，而且还适用于其他任务，如对象检测，这无疑将有利于遥感深度学习技术的发展。

综上所述，本文的主要贡献可以突出如下：

* 提出了一种自级联架构，用于连续地将大规模的上下文信息聚合到小型的上下文中。通过这种方式，可以很好地保留对象和场景之间具有层次依赖关系的全局到局部上下文，从而导致混淆的人造对象的连贯标记结果。
* 提出了一种粗略的改进策略，该策略使用CNN浅层学习的低级特征逐步确定目标对象。因此，可以实现准确的标记结果，尤其是对于结构化的对象。
* 提出了一种残差修正方案，用于校正多特征融合中语义间隙引起的潜在残差。它极大地提高了上述两种不同解决方案的有效性。
* 上述所有贡献构成了一个新颖的语义标签端到端深度学习框架，如图1所示。它在两个具有挑战性的数据集上实现了最先进的性能。

![网络结构图](/img/2019-05-27-1.png)



## 2. 自级联卷积神经网络（ScasNet）

在下文中，我们将描述ScasNet的五个重要方面，包括1）多尺度上下文聚合，2）精细结构对象改进，3）残差校正，4）ScasNet配置，5）学习和推理算法。

### 2.1 多尺度上下文聚合

对VHR图像中混淆人造物体的一致性标记结果是不容易获得的，因为它们具有**高的类内方差和低的类间方差**。为了解决这个问题，仅使用目标对象的局部信息是不够的。我们需要知道它们周围的场景信息，这可以提供更广泛的视觉因素，以更好地区分混乱的对象。场景信息还意味着上下文信息，其表征对象与其周围环境之间的基础依赖性，是对象标识的关键标志。因此，我们讨论如何有效地获取CNN的上下文信息。

在CNN中，较深层（特征图）的每个单元包含更广泛，更强大和抽象的信息，由于其相对于输入图像有较大的感受野和较高的非线性。因此，从更深层获取的上下文可以同时捕获更宽的视觉线索和更强的语义。但是，只有单一尺度的上下文可能不表示对象与其周围环境之间的层次依赖关系。当然，多尺度背景正在受到更多关注。然而，使用常用的融合策略（例如，直接堆叠）很难在不同尺度的上下文中保留**分层依赖性**。为了解决这个问题，我们提出了一种新颖的**自级联架构，如图1中部所示。它旨在聚合全局到局部的上下文，同时保留层次依赖性**，即不同尺度的对象和场景之间的潜在包含和位置关系（例如，汽车更可能在路上，烟囱和天窗是更可能的是屋顶和屋顶的一部分，更可能在路边）。

具体而言，我们**在编码器的最后一层执行扩张卷积运算以捕获上下文**。原因有两方面。一方面，扩张卷积扩展了感受野，可以捕获具有更广泛信息的高级语义。另一方面，虽然从理论上讲，网络高层的特征在输入图像上具有非常大的感受野，但实际上它们要小得多。扩张卷积可以缓解这个问题。为了使扩张卷积后的特征图的大小不变，应当padding。

然后，通过设置一组大到小的扩张率**（实验中的24,18,12和6）**，生成一系列具有全局到局部上下文的特征图。大区域（高级上下文）包含更多语义和更宽的视觉提示，而小区域（低级上下文）则包含更多语义和更宽的视觉提示。同时，由于具有相同的分辨率，所获得的具有多尺度上下文的特征图可以自动对齐。

![a](/img/2019-05-27-3.png)

为了很好地保留多尺度上下文中的层次依赖关系，我们以自级联的方式将它们从全局顺序聚合到局部，如图2(b)所示。这样，首先聚合高扩张率的高层上下文，然后聚合低膨胀率的低层上下文。在形式上，它可以被描述为

![gongshi](/img/2019-05-27-2.png)

实际上，上述聚合规则与视觉机制是一致的，即**高层背景中更广泛的视觉线索可以在整合低层背景中起到指导作用。例如，整个屋顶的视觉印象可以为识别这个屋顶中的烟囱和天窗提供强有力的指导。**

***上述理解为高层特征中显示烟囱和天窗的特征与屋顶特征一致，可以为正确分类烟囱和天窗提供帮助***

### 2.2 精细结构目标refine

除了复杂的人造物体外，错综复杂的结构化物体也增加了VHR图像中准确标记的难度。实际上，由于多个子采样，基于FCN的方法输出的**最终特征图非常粗糙**。例如，VGG-Net中最后一个特征图的大小是输入大小的1/32。因此，**很难恢复对象的低级细节（例如，边界和定位）以进行精确标记，尤其是对于结构化的对象**。

在CNN中，低层特征通常可以被浅层卷积捕获。基于这一观察结果，我们建议使用粗到细的改进策略重新利用低级特征。具体而言，具有精细分辨率的浅层通过跳层连接逐渐重新引入解码器。

使用所提出的改进策略融合这些低级特征是相当有益的。事实上，编码器中不同分辨率的特征图代表了不同层次的语义。因此，由于其固有的语义鸿沟，直接堆叠所有这些特征可能不是一个好的选择。在我们的方法中，当使用渐进融合策略时，减轻了语义鸿沟的影响。另一方面，在训练阶段，跳层连接允许直接将梯度传播到浅层，这有助于端到端训练。

![juti](/img/2019-05-27-4.png)

### 2.3 残差校正

![a](/img/2019-05-27-5.png)

### 2.4 网络配置

**VGG ScasNet**

编码器：VGG （1/8）

自级联：（24， 18， 12， 6）

残差模块：自级联（3个）+ 跳层连接（3个）= 6个

**ResNet ScasNet **

编码器：ReNet （1/8）

自级联：（24， 18， 12， 6）

残差模块：自级联（3个）+ 跳层连接（4个）= 7个

***问题，下采样到1/8，与网络结构图不对应***

### 2.5 训练和推理

loss函数：归一化交叉熵

输入图片尺寸： 400 x 400

batch_size: 4

优化器：SGD（momentum and weight decay are set as 0:9 and 0:0005 ）

学习率：0.01， 每20个epoch降低0.1倍

epoch：about 80

test：多尺度推理（0.5， 1， 1.5）

## 3. 实验

### 3.1 数据集

![SHUJU](/img/2019-05-27-6.png)

### 3.2 实验设置

数据扩充：100pixels重叠裁剪400x400，水平垂直翻转，90旋转

迁移学习：编码器使用pascal voc预训练模型初始化，其余参数使用He初始化

正则化： dropout（0.5）

### 3.3 与深度模型对比

![macai](/img/2019-05-27-7.png)

![a](/img/2019-05-27-8.png)

![b](/img/2019-05-27-9.png)

### 3.4 基准测试比较

![c](/img/2019-05-27-10.png)

![d](/img/2019-05-27-11.png)

### 3.5 多尺度测试

![e](/img/2019-05-27-12.png)

### 3.6 消融实验

![f](/img/2019-05-27-13.png)

![g](/img/2019-05-27-14.png)

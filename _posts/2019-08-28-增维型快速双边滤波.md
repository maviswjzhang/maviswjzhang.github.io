---

layout:     post
title:      增维型快速双边滤波
subtitle:   A Fast Approximation of the Bilateral Filter using a Signal Processing Approach
date:       2019-08-28
author:     Nick
header-img: img/博客背景.jpg
catalog: true
tags:
    - 传统图像处理
---

## 1. 简介

双边滤波非常有用，但速度很慢，因为它是非线性的，传统的加速算法例如在FFT之后执行卷积，是不适用的。本文提出了对双边滤波的新解释，即**高维卷积**，然后是两个非线性操作。其基本思想就是将非线性的双边滤波改成可分离的线性操作和非线性操作。换句话说，原来的双边滤波在图像不同位置应用不同的权重，也就是**位移改变卷积**，他们通过增加一个维度，**也就是将灰度值作为一个新的维度，将双边滤波表达成3D空间中的*线性位移不变卷积*，最后再执行非线性的归一化操作。**

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-1.png)

## 2. 原理

### 2.1 公式推导

**（1） 首先将原始双边滤波公式等式左右皆左乘![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-2.png)，并将两个公式通过二维向量表达成单个公式：**

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-3.png)

**（2）等式右侧乘以Wq，Wq=1：**

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-4.png)

通过以上两步，重新表达了双边滤波，只不过最终还是要将二维向量里面的WI和W做除法归一化

**（3）增维，增加强度维（也就是灰度值）：**

上图中，如果忽略等式右侧的![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-5.png)这一项，那么该等式表达的就是经典的高斯滤波，其可以简写为以下卷积的形式：![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-6.png)。为了将（2）中的等式也表达成位移不变卷积，在形式上引入一个新的维度![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-7.png)，则每个点就可以表示为![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-8.png)，其中（x,y）属于S，![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-7.png)属于R。这样将等式（2）重新表达为以下形式：

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-9.png)

其中，![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-11.png)相当于是一个指示符号，![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-10.png)，也就是说当![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-7.png)为0时，指示符号为1，在本公式中，只有当![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-7.png)=![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-13.png)时，指示符号为1，此时正好和等式2相同。

**（4）符号定义与重新表达：**

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-14.png)

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-15.png)

将等式右侧的最后两项重新表达为下式：

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-16.png)

整个等式则重新表达为：

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-17.png)

上式可以表达为在点（p, Ip）位置处三维卷积的形式：
![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-18.png)

再次简写：

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-19.png)

**（5）整个流程：线性卷积+非线性归一化**

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-20.png)

### 2.2 图文并茂模式

先上一张大图感受一下整个过程，以一维信号为例：

![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-21.png)

**（1）空间与强度维采样与增维：**

这里的采样主要对应上面的连续信号，而我们经常接触的图像为二维离散信号，不需要采样，但是还是要执行增维操作，这个操作主要就是为了得到**wi和w**。现在以二位图像为例，介绍如如何增维，假设图像大小为4x4，取值为1-4，则根据灰度阶1-4确定增加的维度的channels数为4，则wi就是4x4x4，w也是4x4x4维，不同之处是，wi在![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-8.png)处的值不是0就是I(x,y), 而w在![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-8.png)处的值非0即1，如下图所示：
![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-22.png)

**（2）3D卷积：**

分别对wi和w执行三维卷积得到![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-23.png)

**（3）归一化操作division：**

![2019-08-28-24](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-24.png)=![2019-08-28-25](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-25.png) / ![2019-08-28-26](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-26.png)

**（4）降维：三维切片到二维**

![2019-08-28-27](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-29.png)=![img](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-27.png)![2019-08-28-28](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-28.png)

## 3. 进一步加速：降低分辨率处理再插值

加速计算的关键思想是以粗分辨率计算3D卷积。为此，我们证明了wi和w函数可以在不引入重大错误的情况下进行下采样。事实上，我们从未构建过全分辨率的产品空间。这确保了我们方法的良好记忆和速度性能。我们讨论了该策略的实际实现，并分析了所提出技术的准确性和性能。

![2019-08-28-28](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-30.png)

**下采样使用盒式滤波器也就是平均下采样，上采样采用线性上采样，此处使用Ss和Sr分别表示空间维度和强度维度的采样率。**

执行完上图中的上采样步骤之后，依旧要执行division和slice操作。

## 4. 伪代码

![2019-08-28-28](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-31.png)

## 5. python实现

```python
import numpy as np
import math
import scipy.signal, scipy.interpolate
import matplotlib.pyplot as plt
import cv2

def bilateral_approximation(image, sigmaS, sigmaR, samplingS=None, samplingR=None):
    # It is derived from Jiawen Chen's matlab implementation
    # The original papers and matlab code are available at http://people.csail.mit.edu/sparis/bf/

    # --------------- 原始分辨率 --------------- #
    inputHeight = image.shape[0]
    inputWidth = image.shape[1]
    sigmaS = sigmaS
    sigmaR = sigmaR
    samplingS = sigmaS if (samplingS is None) else samplingS
    samplingR = sigmaR if (samplingR is None) else samplingR
    edgeMax = np.amax(image)
    edgeMin = np.amin(image)
    edgeDelta = edgeMax - edgeMin

    # --------------- 下采样 --------------- #
    derivedSigmaS = sigmaS / samplingS
    derivedSigmaR = sigmaR / samplingR

    paddingXY = math.floor(2 * derivedSigmaS) + 1
    paddingZ = math.floor(2 * derivedSigmaR) + 1

    downsampledWidth = int(round((inputWidth - 1) / samplingS) + 1 + 2 * paddingXY)
    downsampledHeight = int(round((inputHeight - 1) / samplingS) + 1 + 2 * paddingXY)
    downsampledDepth = int(round(edgeDelta / samplingR) + 1 + 2 * paddingZ)

    wi = np.zeros((downsampledHeight, downsampledWidth, downsampledDepth))
    w = np.zeros((downsampledHeight, downsampledWidth, downsampledDepth))

    # 下采样索引
    (ygrid, xgrid) = np.meshgrid(range(inputWidth), range(inputHeight))

    dimx = np.around(xgrid / samplingS) + paddingXY
    dimy = np.around(ygrid / samplingS) + paddingXY
    dimz = np.around((image - edgeMin) / samplingR) + paddingZ

    flat_image = image.flatten()
    flatx = dimx.flatten()
    flaty = dimy.flatten()
    flatz = dimz.flatten()

    # 盒式滤波器（平均下采样）
    for k in range(dimz.size):
        image_k = flat_image[k]
        dimx_k = int(flatx[k])
        dimy_k = int(flaty[k])
        dimz_k = int(flatz[k])

        wi[dimx_k, dimy_k, dimz_k] += image_k
        w[dimx_k, dimy_k, dimz_k] += 1

    # ---------------  三维卷积 --------------- #
    # 生成卷积核
    kernelWidth = 2 * derivedSigmaS + 1
    kernelHeight = kernelWidth
    kernelDepth = 2 * derivedSigmaR + 1

    halfKernelWidth = math.floor(kernelWidth / 2)
    halfKernelHeight = math.floor(kernelHeight / 2)
    halfKernelDepth = math.floor(kernelDepth / 2)

    (gridX, gridY, gridZ) = np.meshgrid(range(int(kernelWidth)), range(int(kernelHeight)), range(int(kernelDepth)))
    # 平移，使得中心为0
    gridX -= halfKernelWidth
    gridY -= halfKernelHeight
    gridZ -= halfKernelDepth
    gridRSquared = ((gridX * gridX + gridY * gridY) / (derivedSigmaS * derivedSigmaS)) + \
                   ((gridZ * gridZ) / (derivedSigmaR * derivedSigmaR))
    kernel = np.exp(-0.5 * gridRSquared)

    # 卷积
    blurredGridData = scipy.signal.fftconvolve(wi, kernel, mode='same')
    blurredGridWeights = scipy.signal.fftconvolve(w, kernel, mode='same')

    # ---------------  divide --------------- #
    blurredGridWeights = np.where(blurredGridWeights == 0, -2, blurredGridWeights)  # avoid divide by 0, won't read there anyway
    normalizedBlurredGrid = blurredGridData / blurredGridWeights
    normalizedBlurredGrid = np.where(blurredGridWeights < -1, 0, normalizedBlurredGrid)  # put 0s where it's undefined

    # --------------- 上采样 --------------- #
    (ygrid, xgrid) = np.meshgrid(range(inputWidth), range(inputHeight))

    # 上采样索引
    dimx = (xgrid / samplingS) + paddingXY
    dimy = (ygrid / samplingS) + paddingXY
    dimz = (image - edgeMin) / samplingR + paddingZ

    out_image = scipy.interpolate.interpn((range(normalizedBlurredGrid.shape[0]),
                                           range(normalizedBlurredGrid.shape[1]),
                                           range(normalizedBlurredGrid.shape[2])),
                                          normalizedBlurredGrid,
                                          (dimx, dimy, dimz))
    return out_image


if __name__ == "__main__":
    image = cv2.imread('lena512.bmp', 0)
    mean_image = bilateral_approximation(image, sigmaS=64, sigmaR=32, samplingS=32, samplingR=16)
    plt.figure()
    plt.subplot(121)
    plt.axis('off')
    plt.imshow(image, cmap='gray')
    plt.subplot(122)
    plt.axis('off')
    plt.imshow(mean_image, cmap='gray')
    plt.show()
```

![2019-08-28-28](C:\Users\CV\Documents\GitHub\niecongchong.github.io\img\2019-08-28-32.png)
---
layout:     post
title:      超像素池化用于弱监督语义分割
subtitle:   Weakly Supervised Semantic Segmentation Using Superpixel Pooling Network
date:       2019-07-09
author:     Nick
header-img: img/博客背景.jpg
catalog: true
tags:
    - 论文阅读
---

## 摘要
我们提出了一种基于深度神经网络的弱监督语义分割算法，该算法仅依赖于图像级别标签。所提出的算法在生成分割注释和使用生成的注释学习语义分割网络之间交替。在该框架中成功的关键决定因素是仅在给定图像级标签的情况下构建可靠的初始注释的能力。为此，我们提出了超像素合并网络（SPN），它利用输入图像的超像素分割作为池化层，以反映用于学习和推断语义分割的低级图像结构。然后，使用由SPN生成的初始注释来学习估计像素化语义标签的另一神经网络。分割网络的体系结构将语义分割任务分解为分类和分割，从而使网络从噪声标注中提前学习到与类别无关的形状。事实证明，两个网络对于提高语义分割准确性至关重要。与具有挑战性的PASCAL VOC 2012分割基准的现有技术相比，所提出的算法在弱监督语义分割任务中实现了出色的性能。

## 1. 简介

我们认为单个图像的低层结构和多幅图像中常见的形状信息，可以改进弱监督语义分割。我们使用两个DNNs和一个迭代优化过程来实现这一思想。具体地说，我们的方法是:1)生成分割注释，2)使用生成的注释学习语义分割网络，其中学习的网络又用于生成下一轮的注释。此框架的成功依赖于仅生成图像级类标签的可靠初始注释的能力。为此，我们提出了超像素池网络(Superpixel Pooling Network, SPN)，它采用超像素分割作为池化层，反映低层次图像结构，在弱监督设置下进行学习和推理语义分割。然后给出SPN生成的初始注释，学习DecoupledNet (Hong, Noh, and Han 2015)，这是我们方法中用于最终语义分割的第二个网络。通过将语义分割解耦为分类和分割任务，解耦后的网络可以有效地从初始标注中提前学习到与类无关的形状。根据我们的观察，SPN和DecoupledNet 都大大提高了分割精度。我们的框架在弱监督语义分割中仅通过一轮训练就优于现有的最先进技术，并且它的性能通过额外的一轮训练得到了进一步的提高，其中注释是由前几次迭代的解耦网络生成的。我们的方法的贡献基于以下三个方面：

* 我们提出一种新的DNN架构，利用超像素作为池化层在仅包含图像级标签的情况下生成分割注释。提出的SPN与现有的DecoupledNet 相结合，实现了弱监督语义分割。
* 为了构造鲁棒的训练初始分割标签，我们引入了分割标签清理和可靠的图像识别技术，这有助于提高最终分割性能。
* 该算法具有令人印象深刻的性能，与现有方法相比，其精度达到了最高水平，且具有显著的优势。

## 2. 超像素池化网络

本节描述SPN的体系结构，包括超像素池化层的细节，以及SPN的学习策略。讨论了如何利用SPN计算训练图像的初始分割标注。

SPN由三部分组成:1) 特征编码器$ f_{enc} $, 2)上采样模块：特征上采样$ f_{ups} $ 和超像素池化层组成，3)对编码器和上采样模块得到的特征向量进行分类的两个分类模块。整个网络都是通过最后一个组件计算的两个单独的分类损失来学习的。SPN的总体结构如下图所示。

![1](/img/2019-07-09-01.png)

图1：SPN的总体架构。SPN接受两个输入进行推理:一个图像及其超像素图。对于给定的输入图像，我们的网络使用编码器 $ f_{enc} $ 提取高分辨率的特征图，然后使用多个上采样层$ f_{ups} $ ，超像素池化层利用输入超像素图作为池化布局，将每个超像素内的特征聚集在一起。然后通过训练具有与(Zhou et al. 2016)相似的判别损失模型，得到超像素与语义类别的相关性。注意，我们添加了全局平均池的额外分支用于正则化，这可以防止由超像素引入的训练噪声。

SPN的编码器计算输入图像x的卷积特征图z。作为编码器的一部分，我们采用了在ImageNet上预先训练的VGG16网络，不包括它的全连通层。整个VGG16网络的参数是固定的。为了使编码器适应目标任务，我们在VGG16网络的卷积层之上添加了一个额外的卷积层，这是从头开始学习的。因此，编码器是完全卷积的，并输出包含空间信息的特征图。

给定卷积特征图z，估计目标面积的一种直接方法是对特征图的每个空间位置进行分类，类似于目标检测中的滑动窗方法。为了将这个分类器与其他的网络参数进行联合学习，全局平均池化或全局最大池化将特征映射到单个特征向量,然后利用分类损失学习分类层。 然而，该方法得到的激活图对于语义分割来说是不够的，因为它只给对象的少数识别部分赋了高分，而且分辨率太低，无法准确地恢复对象的形状。

为了解决上述问题，我们设计了超像素池化(SP)层。与传统的池化层不同，SP层的池化布局不是预先定义的，而是由输入图像的超像素决定的。通过SP层，我们可以通过平均池化对超像素空间对齐的特征向量进行聚合。SP层的输出变成一个`N x K`的矩阵，其中N表示输入图像中超像素的个数，K表示feature map中通道的个数(当前SPN架构中K = 512)。与(Zhou et al. 2016)类似，将`N x K`个超像素特征在超像素上取平均值，构建一个`1 x K`向量，然后通过以下全连接层对其进行分类，计算并反向传播分类损失。

利用SP层最简单的方法是直接将feature map和SP层连接起来，但是由于feature map的分辨率太低，这是不合适的; 一个feature map的位置可能与大量的superpixels相关联，导致superpixels的特征向量过于平滑。因此，我们在特征图和SP层之间添加了非线性上采样模块$ f_{ups} $。该模块由两个反卷积层和一个反池化层组成，然后是另外两个反卷积层。每次反卷积后，附加一个批次归一化层BN和一个整流线性单元ReLU。我们在编码器的最后一个池层和反池层之间使用了一个共享池交换机(Noh, Hong, and Han 2015)，这对于在语义分割场景中重构对象结构非常有用。上采样模块的所有参数都是从零开始训练的。

最后，SPN有一个分支，它直接将全局平均池化应用于特征映射z，并对聚合的特征向量进行分类。这个分支的目的是防止网络被SP层破坏，保持高激活分数的有效判别部分。

## 3. 超像素池化层的前向和后向传播

本节介绍超像素池化层的前向和后向传播。让$ P_i = \{{p^k_i}\}   k=1, \cdots, K_i $ 代表一幅图像中的第`i`个超像素，$ {p^k_i} $ 表示第`i`个超像素中的单个像素，$ K_i $表示当前超像素包含的像素数。

前向传播通过超像素池化层回产生特征向量，每一个特征向量是当前超像素内所有的关联像素的平均池化。让$ \hat z =f_{ups}(z) $代表上采样之后的特征图，其是超像素池化层的输入。池化之后第`i`个超像素的特征向量通过下式给出：

![2](/img/2019-07-09-02.png)

其中$r_j$和$\hat z_j$分别表示感受野和$\hat z$特征图第`j`个位置的特征向量。$I(p^k_i \in r_j)\hat z_j$是一个指示函数。

这个公式写的让人难以捉摸，具体来说就是先索引出当前超像素对应的$\hat z$上的像素位置，再对这些位置上的特征向量取平均。

通过对所有超像素的全局平均池化，得到输入图像的单个特征向量，由下式给出：

![3](/img/2019-07-09-03.png)

其中N表示超像素的个数。然后利用SP层之后的全连通层对图像级特征向量$\tilde z$进行分类，并将分类结果喂给给损失函数$L$。

在反向传播中，得到输入特征图$ \hat z_j$的梯度为:

![4](/img/2019-07-09-04.png)

请注意，尽管一个batch中的单个输入图像可能具有不同数量的超像素，但是由于每个图像上所有超像素的平均池化，正向和反向传播并不依赖于超像素的数量。

## 4. 学习超像素池化网络

### 4.1 损失函数

SPN是通过分类损失来学习的，因为在我们的设置中只有图像级的类标签可用。由于一个图像中可能出现多个不同类的对象，给定C个类对象，我们的损失函数定义为C个二分类损失之和，如下所示：

![5](/img/2019-07-09-05.png)

其中$f_c(x)$和$y_c \in \{0,1\}$分别是单个类$c$的网络输出和ground-truth标签。注意，SPN在两个分支的末端输出两个类得分向量(图1)，它们由相同的损失函数独立处理。

### 4.2 多尺度学习。

物体在图像中以不同的比例表示。为了更好地建模对象的这种尺度变化，我们采用了(Oquab et al. 2015)的方法，该方法在训练期间随机调整输入小批量图像的大小。具体来说，我们首先通过填充0到更短的维度来使图像变成正方形，然后随机地将它们重新调整为6个预定义的大小之一:$250^2$、$300^2$、$350^2$、$400^2$、$450^2$和$500^2$像素。注意，除了SP层，SPN只包含卷积层和全局池化层，所以如果SP层可以处理不同大小的图像，那么网络自然适合这种多尺度方法。为此，我们针对每个图像预先计算所有6种可能的输入分辨率的感受野的范围（即式(1)中的$h^j_i$）。我们从经验上观察到，这种多尺度方法有助于更准确地估计目标区域。

## 5. 使用SPN超像素池化网络生成初始注释

### 5.1 超像素池化类激活图

SPN通过SP层为每个超像素分配一个特征向量，如式(1)所示。在推理过程中，首先将每个超像素的特征向量赋予SP层之后的全连接分类层，计算各个超像素的类分数。因此，我们得到了$R^{W \times H \times C}$中的一个张量，其中W和H分别是输入图像的宽度和高度，每个通道对应的相关类的激活映射。与训练中一样，输入图像被重新调整为6个预定义的大小，并相应地计算6个激活张量。最后，通过最大池化对6个张量进行聚合。我们将聚合张量称为超像素池类激活图(SP-CAM)。

SP-CAM是由(Zhou et al. 2016)的类激活映射(Class Activation Map, CAM)驱动的，但具有关键的优势。与CAM不同的是，在CAM中，特征图的每个位置都是独立激活的，SP-CAM将类激活分配给单个超像素，这允许在保留图像结构的原始分辨率下生成类激活得分。SP-CAM的这一特性对于语义分割特别有用，如图2所示。

![1562720560834](/img/2019-07-09-06.png)

图2:CAM (Zhou et al. 2016)与我们的SP-CAM的定性比较与阈值化得到的初始分割结果。计算CAM的方法是将feature map $z$的每个位置进行分类，将全连接层直接连接到$z$上，由于CAM在有限分辨率下局部激活，无法覆盖整个目标区域。利用超像素作为形状估计单元，使SP-CAM中的类激活更精确地保留了对象的形状。

### 5.2 使用SP-CAM生成初始注释。

通过训练图像的SP-CAM获得训练图像的初始分割标注。SP-CAM中每个类的激活图的阈值为该激活图最大得分的50%;换句话说，激活分数低于阈值的像素将被忽略。此外，我们忽略了与像素级ground-truth标签不匹配的类的激活映射。我们将此步骤称为注释清理。注意，使用图像级标签并不是不公平的，因为我们的目标不是对分割标签进行推理，而是在给定图像级分类标签的情况下，构造训练图像的分割注释。然后通过搜索每个像素中激活分数最大的标签，给出SP-CAM的分割标注。如果一个像素在所有C通道中的激活分数都低于预定义的阈值，则将其视为背景。图2给出了一个初始注释示例。

## 6. 解耦网络的迭代学习

由于使用超像素作为形状估计单元，SPN的输出已经产生了像样的分割结果。然而，SPN仍然存在着判别性学习的局限性; 它倾向于夸大具有鉴别能力的超像素的类分数，因此当上面描述的过程生成初始注释时，对象的某些部分可能会丢失。解决这一问题的一种方法是从其他图像的注释中得到提示，通过从大量的初始分割注释中学习与类无关的分割知识，可以实现这一思想。我们采用DecoupledNet (Hong, Noh, and Han 2015)作为网络，从初始标注中学习分割知识，并迭代细化。

DecoupledNet 将语义分割问题分解为分类和分割两个独立的任务，并由两个解耦网络来处理这两个任务。接下来(Hong, Noh, and Han 2015)，解耦网络的分类网络使用图像级标签进行训练，在我们的框架中作为特征编码。然而，与最初的设置不同，它的分割网络现在使用生成的有噪声的注释来训练，而不是分割的真值。由于二值分割网络是跨不同类对象共享的，解耦后的网络可以从多个类对象的注释中学习到与类无关的分割知识，从而为下一轮训练生成更准确的注释。

在我们算法的每一轮中，DecoupledNet 都是从生成的注释中学习的，这些注释在第一轮由SPN提供，在第二轮由上一轮迭代训练的DecoupledNet 提供。为了避免上一轮的标注偏差，我们每一轮都从头开始学习DecoupledNet 的分割网络。请注意，只有一小部分可靠的注释用于了解网络，以最小化不完整和有噪声的注释带来的不良影响。为此，我们根据散度定义注释的可靠性，散度是注释中周长的平方与分段面积的比值。然后，只选择最少散度的注释的子集进行培训，同时假设较少散度的注释更可靠。注意，DecoupledNet 非常适合这种可靠的子集选择，因为即使在训练中只给出有限数量的分割注释，网络也显示出了优越的性能。我们从经验上观察到，使用一组可靠注释学习的DecoupledNet 始终优于使用所有注释学习的DecoupledNet 。经过训练的DecoupledNet 用于为下一轮生成注释。与SPN一样，生成的注释由图像级标签进行清理，以删除注释中不相关或不可靠的段。

重复上述过程，直到达到预定义的迭代次数为止。最后一轮训练的DecoupledNet 作为语义分割的模型。

## 7. 实验

本节描述了实现细节，并通过与最先进的弱监督语义分割技术进行比较，展示了我们在PASCAL VOC 2012分割基准(Everingham et al. 2010)中的方法的有效性。作为一种评价指标，我们采用了地面真值与预测分割的IoU评定分割精度。

### 7.1 实现细节

SPN和DecoupledNet 都是在PASCAL VOC 2012数据集上训练的(Everingham et al. 2010)。除了提供用于语义分割任务的图像集外，我们还使用了(Hariharan et al. 2011)中使用的额外图像来扩大训练集。我们总共使用了10582幅图像来训练网络，并保留了1449幅图像的验证集来评估我们的方法。图像的超像素由(Zitnick和Dollar 2014)计算。

SPN在Torch7中实现(Collobert、Kavukcuoglu和Farabet 2011)。Adam (Ba和Kingma 2015)对网络参数进行了优化，初始学习率为0.001。经过约9K次迭代后，mini-batch为12。在我们的实验中，单台拥有12Gb内存的Nvidia TITAN X GPU上的训练过程大约需要3个小时。

我们学习DecoupledNet 两轮。学习DecoupledNet 时，我们遵循(Hong, Noh, and Han 2015)中描述的原始设置，两轮迭代的次数都设置为9K。作为训练集，每轮每个类都选择最可靠的300个注释。

## 8. PASCAL VOC基准评价

### 8.1 生成注释的分析

我们首先分析并评估算法在每一轮生成的注释。具体结果如图3所示。结果表明，对注释进行清理和可靠的子集选择是提高注释质量和学习更好的分割网络的关键。

我们还将SPN与CAM (Zhou et al. 2016)在注释质量方面进行了比较。由于没有可靠的子集选择，SPN生成的注释的平均准确率为43.8%，CAM生成的注释的平均准确率为30.5%。该结果验证了SPN超像素池层的有效性。

![ww](/img/2019-07-09-07.png)

图3:我们在PASCAL VOC 2012分割基准上的标注生成技术分析。**(a)可靠性指标的经验证明。**我们给出了训练图像中按可信度递减顺序选取的标注的平均分割精度。随着所选注释数量的增加，平均精度不断下降，这表明可靠性度量与注释的实际质量有很好的相关性。**(b)注释清理和可靠子集选择的效果。**在这两轮中，通过对注释进行清理，提高了注释的准确性，并在训练集中每类选择300条最可靠的注释，进一步提高了注释的准确性。**(c)可靠子集选择的效果。**我们训练了两个网络，一个包含所有经过过滤的注释，另一个每个类包含300个最可靠的注释，并在验证集中比较了它们的分割预测精度。

### 8.2 与其他方法比较

并与最新的弱监督方法进行了比较。除了我们的两个分割网络(我们的:Rnd1，我们的:Rnd2)，我们还评估了SPN作为一个语义分割网络(我们的:SPN)。SPN预测语义分割的方法与生成初始标注的方法相同，但在分割结果中利用分类分数代替图像标签忽略无关类。特别地，SPN忽略了那些在所有超像素上的平均激活分数都低于0的对象类。我们还报告了用所有可用的ground truth(上界)作为算法上界训练的DecoupledNet 的准确性。

对PASCAL VOC 2012验证集的分割结果进行量化比较，如表1所示。SPN本身的性能优于除了使用分割建议框(MIL+Seg)MIL之外的所有的方法，这是其中最好的一种。需要注意的是，与SPN的超像素相比，MIL+Seg中使用的分割建议在恢复对象形状方面是更昂贵和更有力的证据，而SPN在使用超像素(MIL+Spx)时，与SPN一样，SPN的性能优于MIL。此外，仅通过一轮解耦网络训练，我们的系统就大大优于MIL+Seg，另外一轮训练进一步提高了性能。同样的趋势也体现在PASCAL VOC 2012测试集的结果中，如表2所示。

![sss](/img/2019-07-09-08.png)

PASCAL VOC 2012验证集定性结果如图4所示，其中我们的系统(Round1和Round2)与经过清理(初始批注)后的SPN结果进行对比。从图中可以看出，随着迭代的进行，丢失的部分被恢复，错误的警报被抑制。

![ss](/img/2019-07-09-09.png)

## 9. 结论

提出了一种基于超像素池网络的弱监督语义分割算法。SPN利用底层图像结构，采用超像素映射作为池布局，这对于弱监督环境下的语义分割特别有用。然后将SPN的分割结果作为学习DecoupledNet 的像素级分割标注，从标注中学习与类无关的分割知识，进一步提高分割结果。为了减轻噪声和不完整注释带来的副作用，我们还提出了对注释进行清理和度量其可靠性的技术。在一个具有挑战性的基准数据集上，与以前的技术相比，该算法的性能有了很大的提高。

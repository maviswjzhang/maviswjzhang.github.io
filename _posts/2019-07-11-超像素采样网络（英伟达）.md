---
layout:     post
title:      超像素采样网络
subtitle:   Superpixel Sampling Networks
date:       2019-07-11
author:     Nick
header-img: img/博客背景.jpg
catalog: true
tags:
    - 可借鉴领域
	- 论文阅读
---

## 摘要
超像素为图像数据提供了一种高效的低/中层次的表示，大大减少了后续视觉任务的图像基元数量。现有的超像素算法是不可微的，这使得它们很难集成到其他端到端可训练的深度神经网络中。我们开发了一种新的超像素采样可微模型，利用深度网络学习超像素分割。所得到的超像素采样网络(SSN)是端到端可训练的，允许学习任务特定的超像素，具有灵活的损失函数和快速的运行时间。大量的实验分析表明，SSNs不仅在传统的分割基准上优于现有的超像素算法，而且可以学习超像素用于其他任务。此外，SSN可以很容易地集成到下游深度网络中，从而提高性能。

## 1. 简介

超像素是一种基于图像底层属性对图像像素[33]进行分组而形成的图像过分割。它们提供了一种视觉上有意义的图像内容棋盘分布，从而减少了用于后续图像处理的图像基元的数量。由于他们的表征和计算效率,超像素已经成为公认的低/中层图像表示并被广泛用于计算机视觉算法如目标检测，语义分割，显著性估计，光流估计，深度估计，跟踪等。超像素在传统的能量最小化框架中得到了广泛的应用，其中图像基元的数量较少，极大地降低了优化的复杂度。

近年来，针对广泛的计算机视觉问题，采用深度学习的案例急剧增加。除了一些方法(如[13,18,34])，超像素很少与现代深度网络结合使用。这主要有两个原因。首先，**大多数深层结构的基础是标准卷积运算，它通常是在规则网格格上定义的，当在不规则超像素格上运行时，它的效率会降低。**其次，**现有的超像素算法是不可微的**，因此在深度网络中使用超像素会引入不可微模块。

在这项工作中，我们提出了一种新的超像素分割的深度可微算法来缓解第二个问题。我们首先回顾了广泛使用的简单线性迭代聚类(SLIC)超像素算法[1]，并通过放松SLIC中存在的最近邻约束，将其转化为可微算法。这种新的可微算法允许端到端训练，并使我们能够利用强大的深度网络学习超像素，而不是使用传统的手工制作的特征。这种深度网络与可微SLIC的结合形成了我们的端到端可训练的超像素算法，我们称之为超像素采样网络(SSN)。图1给出了所提出的SSN的概述。给定的输入图像首先通过在每个像素处产生特征的深层网络传递。然后将这些深层特征传递到可微SLIC上，SLIC执行迭代聚类，生成所需的超像素。整个网络是端到端可训练的。SSN的可微特性允许使用灵活的损失函数来学习特定任务的超像素。图1显示了一些SSN生成的超像素样本。

![ss](/img/2019-07-11-01.png)

图1:超像素采样网络概述。给定的图像首先被传递到一个深度网络中，该网络提取每个像素的特征，然后可微SLIC使用这些特征来生成超像素。这里显示了两个例子，SSN生成的超像素用于语义分割和光流。

在BSDS500[4]、Cityscapes[10]和PascalVOC[11]三种不同的分割基准数据集上的实验结果表明，所提出的超像素采样网络(SSN)与现有的著名超像素算法相比，具有更好的性能，而且速度更快。我们还证明，通过简单地将SSN框架集成到现有的使用超像素的语义分割网络[13]中，可以实现性能的改进。此外，我们还证明了SSN在学习超像素以完成其他视觉任务方面的灵活性。具体来说，在Sintel光流数据集[7]上的概念验证实验中，我们演示了如何学习更符合光流边界而不是标准对象边界的超像素。与现有的超像素算法相比，该算法具有以下优点:

* 可端到端训练：SSN是端到端可训练的，可以很容易地集成到其他深度网络架构中。据我们所知，这是第一个端到端可训练的超像素算法。
* 灵活的和特定于任务：SSN允许使用灵活的损失函数进行学习，从而学习特定于任务的超像素。
* 最先进的性能：在广泛的基准数据集上的实验表明，SSN优于现有的超像素算法。
* 优异的运行时间：SSN在运行时间方面也优于著名的超像素算法，使它能够在大型数据集上学习，并对实际应用有效。

## 2. 相关工作

### 2.1 超像素算法

传统的超像素算法可分为基于图的算法和基于聚类的算法。基于图的方法将超像素分割问题描述为图的分割问题，图节点由像素表示，边缘表示相邻像素之间的连通性强度。通常，图的划分是通过求解离散优化问题来实现的。在这类算法中广泛使用的算法包括归一化剪切[33]、Felzenszwalb和Huttenlocher (FH)[12]以及熵率超像素（ERS）[26]。由于离散优化涉及离散变量，优化目标通常是不可微的，因此很难结合基于图的方法和深度网络。

另一方面，基于聚类的方法利用传统的聚类技术(如k-means)进行超像素分割。这类算法中广泛使用的算法有SLIC[1]、LSC[25]和流形SLIC[27]。这些方法主要进行k均值聚类，但在特征表示上存在差异。SLIC[1]将每个像素表示为一个5维位置和Lab颜色特征(XY Lab特征)，而LSC[25]方法将这些5维特征投射到一个10维空间中，并在投影空间中执行聚类。另一方面，流形SLIC[27]使用二维流形特征空间进行超像素聚类。虽然这些聚类算法需要迭代更新，但在SNIC方法[2]中提出了一种用于超像素分割的非迭代聚类方案。该方法也是一种基于聚类的方法。然而，与现有技术不同，我们利用深度网络通过端到端训练框架学习超像素集群的特性。

最近的一篇调查论文[36]详细介绍了超像素分割的其他技术，包括分水岭变换[29]、几何流[24]、图割[39]、均值平移[9]和爬山[5]。然而，这些方法都依赖于手工制作的特性，将深度网络集成到这些技术中并非易事。最近的SEAL[38]技术提出了一种通过不可微超像素算法绕过梯度来学习超像素分割的深层特征的方法。与我们的SSN框架不同，SEAL不是端到端可微的。

### 2.2 深度聚类

受监督任务深度学习成功的启发，几种方法研究了使用深度网络进行无监督数据聚类。最近，Greff等人[17]提出了神经期望最大化框架，利用深度网络对聚类标签的后验分布进行建模，并展开EM过程中的迭代步骤进行端到端训练。在另一项工作[16]中，利用梯形网络[31]对一个层次潜在变量模型进行聚类。Hershey 等人提出了一种基于深度学习的音频信号分类框架。Xie 等人提出了一种深度嵌入式聚类框架，用于同时学习特征表示和聚类分配。在最近的一篇调查论文中，Aljalbout 等人[3]对基于深度学习的聚类方法进行了分类。本文还提出了一种基于深度学习的聚类算法。不同于以往的工作，我们的算法是针对超像素分割任务，我们使用特定的图像约束。此外，我们的框架可以很容易地结合其他视觉目标函数学习任务特定的超像素表示。

## 3. 基础知识

SSN的核心是一种可微聚类技术，其灵感来自于SLIC[1]超像素算法。在这里，我们简要回顾了SLIC，然后在下一节描述我们的SSN技术。SLIC是最简单的超像素算法之一，也是应用最广泛的超像素算法之一。该方法易于实现，运行速度快，并且生成紧凑一致的超像素。

虽然SLIC算法有几种不同的变体[25,27]，但在原始形式中，SLIC是一种对图像像素在五维位置和颜色空间(通常缩放为XY Lab空间)上执行的k-means聚类。在形式上，给定一幅图像$I \in R^{n \times 5}$，有$n$个像素，每个像素有5维特征，超像素计算的任务是将每个像素分配给$m$个超像素中的一个，即计算像素-超像素关联图![ss](/img/2019-07-11-02.png)。SLIC算法的操作如下。首先，我们在5维空间中采样初始簇(超像素)中心$S^0 \in R^{m \times 5}$。这种采样通常是均匀地跨像素网格进行的，并基于图像梯度进行一些局部扰动。给定这些初始的超像素中心$S^0$, SLIC算法以迭代的方式进行，在每个迭代t中执行以下两个步骤:

* **像素-超像素关联**：将每个像素关联到五维空间中最近的超像素中心，即，分配每个像素$p$新的超像素：

![ss](/img/2019-07-11-03.png)

其中D表示距离计算$D(a, b) = ||a - b||^2$。

* **超像素中心更新**：将每个超像素关联的所有超像素的5维特征取平均得到新的超像素聚类中心$S^t$：

![ss](/img/2019-07-11-04.png)

其中$Z^t_i$表示超像素簇$i$中的像素个数。

这两个步骤构成了SLIC算法的核心，并不断重复，直到收敛或进行固定次数的迭代。由于计算式1中所有像素与超像素之间的距离D非常耗时，所以这种计算通常被限制在每个超像素中心周围的一个固定的邻域内。最后，根据应用程序的不同，有一个可选步骤，用于在每个超像素集群中的像素之间加强空间连接。关于SLIC算法的更多细节可以在Achanta等人的[1]中找到。在下一节中，我们将说明如何修改SLIC算法来开发SSN。

## 4. 超像素采样网络

如图1所示，SSN由两部分组成：**生成像素特征的深度网络**，然后将其传递给**可微SLIC**。在这里，我们首先描述可微SLIC，然后是SSN架构。

### 4.1可微SLIC

为什么不可微?通过对SLIC中所有计算结果的仔细分析，我们发现这种不可微性是由像素.超像素关联的计算引起的，它涉及到不可微的最近邻操作。这种最近邻计算也是SLIC超像素聚类的核心，因此我们无法避免这种操作。

我们的方法的一个关键是将最近邻操作转换为可微操作。我们不计算硬的像素-超像素关联![ss](/img/2019-07-11-02.png)，而是计算像素与超像素之间的软关联$Q \in R^{n \times m}$。具体来说，对于$t$次迭代时的像素$p$和超像素$i$，我们将SLIC中的最近邻计算(Eq. 1)替换为以下像素-超像素关联：

![ss](/img/2019-07-11-05.png)

相应地，新的超像素聚类中心的计算(式2)修改为像素特征的加权和:

![ss](/img/2019-07-11-06.png)

其中，![ss](/img/2019-07-11-07.png)是归一化常数。为了方便起见,我们把列归一化$Q^t$表示为$\hat Q^t$,因此我们可以把上述超像素中心更新为![ss](/img/2019-07-11-08.png)。Q的大小是$n \times m$, 甚至少量的超像素$m$,计算所有像素和超像素之间的关联也是十分费时的。因此，我们将每个像素的距离计算限制为仅9个周围的超像素，如图2中的红色和绿色框所示。对于绿色框中的每个像素，只考虑红色框中周围的超像素来计算关联。这将Q的大小从$n \times m$降低到$n \times 9$，使得它在计算和内存方面都非常高效。在Q计算中的这种近似在本质上类似于SLIC中的近似最近邻搜索。

![ss](/img/2019-07-11-09.png)

图2: 从初始网格到学习超像素。一个来自BSDS500数据集的示例可视化结果显示了初始超像素网格和使用$SSN_{pix}$和$SSN_{deep}$获得的超像素。为了计算绿色框中每个像素的像素-超像素关联，只考虑红色框中周围的超像素。

现在，每个SLIC迭代中的计算都是完全可微的，我们将这种改进算法称为可微SLIC。从经验上看，用可微SLIC中的软关联代替SLIC中的硬关联不会导致性能下降。由于这种新的超像素算法是可微的，可以很容易地集成到任何深度网络架构中。我们可以利用深度特征提取器，对整个网络进行端到端的训练，而不是使用手工设计的像素特征$I_p$。换句话说，我们将上述计算(式3和4)中的图像特征$I_p$替换为使用深度网络计算的$k$维像素特征$F_p \in R^{n \times k}$。我们将这种深度网络与可微SLIC的耦合称为超像素采样网络(SSN)。

算法1概述了SSN中的所有计算步骤。算法从深度图像特征提取使用CNN(第1行)。我们用平均像素特征初始化超像素集群中心(2行)，初始化为规则超像素网格(图2)。然后,$v$次迭代,我们迭代更新像素-超像素关联和超像素中心,利用上述计算(3 - 6行)。尽管可以直接为几个下游任务使用软像素-超像素关联Q，但是根据应用程序的需要，可以选择将软关联转换为硬关联(第7行)。此外，就像在原始的SLIC算法中一样，我们可以选择性地在每个超像素集群中的像素之间加强空间连接。这是通过将超像素(小于某个阈值)与周围的超像素合并，然后为每个空间连接的组件分配一个惟一的集群ID来实现的。注意，这两个可选步骤(第7,8行)是不可微的。

![ss](/img/2019-07-11-10.png)

#### 像素和超像素表示之间的映射

对于一些使用超像素的下游应用程序，像素表示被映射到超像素表示上，反之亦然。传统的超像素算法,提供硬的聚类,这从像素映射到超像素表示是通过在每个集群内取平均(Eq.2)。从超像素逆映射到像素表示是通过分配相同的超像素特征给所有属于当前超像素的像素。我们也可以使用与SSN超像素相同的像素-超像素映射，使用从SSN获得的硬聚类(算法1中的第7行)。然而，由于这种硬关联的计算是不可微的，因此在集成到端到端可训练系统时，可能不希望使用硬聚类。值得注意的是，SSN生成的软像素-超像素关联也可以很容易地用于像素和超像素表示之间的映射。Eq. 4已经描述了从像素到超像素表示的映射，这是一个简单的矩阵乘法，通过转置列归一化的$Q$矩阵:![ss](/img/2019-07-11-11.png)，其中F和S分别表示像素表示和超像素表示。将行标准化Q(记作$\tilde Q$)与超像素表示![ss](/img/2019-07-11-12.png)，实现超像素到像素表示的逆映射。因此，将像素-超像素特征映射作为与关联矩阵的简单矩阵乘法给出，并且是可微的。稍后，我们将在设计训练SSN的损失函数时使用这些映射。

### 4.2 网络结构

图3为SSN网络结构示意图。用于特征提取的CNN由一系列卷积层组成，这些卷积层之间穿插着批量归一化[21]BN和ReLU激活。我们使用max-pooling，它在第2层和第4层卷积之后，将输入采样降低2倍，以增加感受野。我们先对第4层和第6层卷积层的输出进行采样，然后与第2层卷积层的输出进行连接，传递到最后的卷积层。我们使用了3个卷积滤波器，除了最后一个输出$k-5$个通道的CNN层外，每个层的输出通道数都设置为64个。我们将这个$k-5$个通道输出与给定图像的XY Lab连接起来，得到k维像素特征。我们选择CNN架构是因为它的简单和高效。其他网络架构也是可以想象的。得到的k维特征被传递到可微SLIC的两个模块上，这两个模块迭代更新像素-超像素关联和超像素中心，总共$v$次迭代。整个网络是端到端可训练的。

![ss](/img/2019-07-11-20.png)

图3: SSN的计算流程。我们的网络由一系列的卷积层组成，这些卷积层之间穿插着批量范数(BN)和ReLU。$\uparrow$为原始图像分辨率的双线性上采样。然后将CNNs的特征传递到可微SLIC的迭代更新中，生成超像素。

### 4.3 学习特定任务的超像素

端到端可训练SSN的主要优点之一是在损失函数方面的灵活性，我们可以使用它来学习特定任务的超像素。就像在任何CNN中一样，我们可以将SSN与任何特定任务的损失函数结合起来，从而学习为下游计算机视觉任务优化的超像素。在本文中，我们重点研究了超像素的表示效率优化问题，例如：学习能够有效表示场景特征的超像素，如语义标签、光流、深度等。例如，如果我们想学习将要用于下游语义分割任务的超像素，那么最好生成符合语义边界的超像素。为了优化表征效率，我们发现任务**特定重构损失**和**紧致度损失**的组合具有良好的性能。

#### 4.3.1 特定任务的重建损失函数

我们用$R \in R^{n \times l}$表示我们希望用超像素高效表示的像素属性。例如，R可以是语义标签(one-hot形式)或光学图。需要注意的是，我们在测试期间得不到R，即， SSN只使用图像数据预测超像素。我们只在训练期间使用R以便SSN可以学会预测适合表示R的超像素。如前4.1节所述,我们可以使用列归一化关联矩阵$\hat Q$将像素特征映射到超像素![ss](/img/2019-07-11-13.png)。超像素表示$\breve R$然后通过![ss](/img/2019-07-11-14.png)映射回像素表示$R^*$，其中$\tilde Q$表示行归一化关联矩阵。然后给出了重建的损失：

![ss](/img/2019-07-11-15.png)

其中$L(.)$表示特定任务的丢失函数。在本工作中，对于分割任务，我们使用交叉熵损失，对光流使用L1-norm学习超像素。其中Q为可微SLIC最终迭代后的关联矩阵$Q^v$。为了方便，我们省略了$v$。

#### 4.3.2 紧致度损失

除了上述损失，我们还使用了紧度损失来鼓励超像素在空间上紧凑，即，使每个超像素簇内的空间方差更小。设$I^{xy}$表示位置处的像素特征。我们首先将这些位置处的特征映射到超像素表示中，即$S^{xy} = \hat Q^T I^{xy}$。然后,我们再逆映射到像素表示使用硬关联$H$,而不是软关联$Q$,通过分配相同的超像素特征给所有属于当前超像素的特征:

![ss](/img/2019-07-11-16.png)

紧致度损失被定义为以下L2范数：

![ss](/img/2019-07-11-17.png)

这种损失鼓励超像素具有更低的空间方差。SSN的灵活性允许使用许多其他损失函数，这使得未来的研究很有趣。总体损失我们在这项工作中使用的组合这两个损失函数,![ss](/img/2019-07-11-18.png)，λ设置为$10^5$。

### 4.4 实验设置

在Caffe神经网络框架[22]中，利用CUDA实现了可微SLIC作为神经网络层。所有的实验都是使用带有Python接口的Caffe来执行的。我们使用了XY Lab 特征作为SSN的输入,位置和颜色特征尺度分别表示为$γ_{pos}$和$γ_{color}$。$γ_{color}$的取值是独立于超像素的数量，并被设置为0.26，其中颜色值从0到255之间不等。$γ_{pos}$的价值取决于超像素:

![ss](/img/2019-07-11-19.png)

 $m_w$,$n_w$和$m_h$, $n_h$表示超像素和像素分别沿着图像的宽度和高度。在实验中,我们观察到$η= 2.5$表现良好。

对于训练，我们使用图片大小为201x201，包含100个超像素。在数据增强方面，我们使用左右翻转，对于较小的BSDS500数据集[4]，我们使用额外的数据增强包括随机缩放图像块。所有实验均采用Adam随机优化[23]，批量为8，学习率为0.0001。除非特别提到，我们训练了500个迭代，并根据验证精度选择最终的训练模型。对于消融学习，我们训练了模型200K迭代。需要注意的是，我们使用一个训练好的SSN模型，通过上面描述的，缩放输入位置特征来估计不同数量的超像素。我们使用可微SLIC的5次迭代(v = 5)进行训练，并在测试时使用了10次迭代，因为我们发现随着迭代次数的增加，性能只获得了很小的提高。参考https://varunjampani.github.io/ssn/查看代码和训练好的模型。

## 5. 实验

我们对4个不同的基准数据集进行了实验。我们首先通过在著名的超像素基准BSDS500[4]上的实验来演示学习超像素的使用(第5.1节)。然后，我们演示了在Cityscapes[10]和PascalVOC[11]数据集中使用任务特定的超像素进行语义分割(第5.2节)，以及在MPI-Sintel[7]数据集进行光流(第5.3节)。此外，我们还演示了SSN超像素在使用超像素的下游语义分割网络中的应用(第5.2节)。

### 5.1学习超像素

我们在BSDS500基准数据集[4]上进行消融研究，并与其他超像素技术进行对比评估。BSDS500由200个训练、100个验证和200个测试图像组成。每个图像都包含多个注释者标注的注释图像。我们将每个注释作为一个单独的示例处理，得到1633个训练/验证对和1063个测试对。

为了学习符合真值分割的超像素，我们在重构损失中使用GT分割标签(Eq. 5)，具体来说，我们将每张图像中的GT分割表示为一个one-hot向量，并将其作为重构损失中的像素属性R。我们在式5中对损失函数L使用交叉熵损失。注意，与语义分割任务中GT标签有意义不同，此数据集中的GT分割不携带任何语义。这并不对我们的实验设置构成任何问题，因为SSN和重建损失是对像素属性R的意义一无所知。重建的损失值使用给定的输入信号R和他的重构值$R^*$,并且不需要考虑R的意义。

#### 5.1.1 评价指标

超像素在许多视觉任务中都很有用，有几种度量超像素的方法。在这项工作中，我们将可实现的分割精度**(ASA)**作为我们的主要度量标准，同时报告**边界度量**，如**边界召回率(BR)和边界精准率(BP)**。ASA评分表示在超像素上执行的任何分割步骤所能达到的精度上限。另一方面，边界精度和召回度度量超像素边界与GT边界的对齐程度。我们将在补充材料中更详细地解释这些度量。这些分数越高，分割结果越好。我们通过改变生成的超像素的平均数量来报告平均ASA和边界度量。对边界精度和查全率的公平评估要求超像素在空间上是连通的。因此，为了无偏比较，我们遵循可选的后处理（line7-8）计算硬聚类，并且强制空间联通。

#### 5.1.2 消融研究

我们参考图3所示的主要模型，深度网络中有7个卷积层，称为$SSN_{deep}$。作为一个基线模型，我们评估了用可微SLIC生成的以像素XY Lab特征为输入的超像素。这类似于标准的SLIC算法，我们称之为$SSN_{pix}$，它没有可训练的参数。作为另一个基线模型，我们用一个学习线性变换输入XY Lab特征的卷积层替换了深度网络，我们称之为$SSN_{linear}$。

![ss](/img/2019-07-11-21.png)

图4: BSDS500的消融研究。图4为不同特征维数$k$和迭代次数$v$的模型在可微SLIC中的平均ASA和BR得分。测试集结果表明，深度网络显著提高了ASA和BR的得分，特征维数k和可微SLIC迭代v越高，ASA和BR的得分越高。

我们选择$k = 20和v = 10$，从这里开始将这个模型称为$SSN_{deep}$。

#### 5.1.3 与最先进的技术相比较

图5为SSN与最先进的超像素算法的ASA和precision - recall比较。我们比较了以下主要算法:SLIC[1]、SNIC[2]、seed[5]、LSC[25]、ERS[26]、ETPS[45]和SCALP[14]。从图中可以看出，SSNpix的性能与SLIC超像素的性能类似，这表明在放松最近邻约束时，SLIC的性能并没有下降。与其他技术的比较表明，SSN在ASA评分和精确回忆两方面都有较好的表现。图2是比较$SSN_{pix}$和$SSN_{deep}$的可视化结果，图7是比较$SSN_{deep}$和最新技术的可视化结果。请注意，$SSN_{deep}$超像素平滑地遵循对象边界，并且更集中于对象边界附近。

![ss](/img/2019-07-11-22.png)

![ss](/img/2019-07-11-23.png)

### 5.2 超像素用于语义分割

在本节中，我们给出了Cityscapes[10]和PascalVOC[11]的语义分割基准的结果。实验设置与前一节非常相似，唯一不同的是在重构损失中使用语义标签作为像素属性R。因此，我们鼓励SSN学习符合语义分割的超像素。

#### 5.2.1 Cityscapes 

Cityscapes是一种具有像素精确语义标注的大规模城市场景理解基准数据集。我们用2975张训练图像训练SSN，并对500张验证图像进行评估。为了便于实验，我们使用半分辨率(512 x 1024)的图像进行实验。图6中的曲线图显示，$SSN_{deep}$在ASA方面的表现与SEAL [38] 相当，而在准确率方面则更好。我们在图7中显示了一个可视化的结果，补充了更多的内容。

![ss](/img/2019-07-11-24.png)

![ss](/img/2019-07-11-26.png)

#### 5.2.2 运行时分析

我们报告了不同技术的近似运行时，用于在表1中计算512x102的cityscapes图像上的1000个超像素。我们使用NVIDIA Tesla V100 GPU计算GPU运行时。$SSN_{pix}$和$SSN_{deep}$的运行时比较表明，SSN计算时间的很大一部分是由于可微SLIC。运行时表明，SSN比几种超像素算法的实现快得多。

![ss](/img/2019-07-11-25.png)

#### 5.2.3 PascalVOC

Pascal VOC 2012[11]是另一种广泛使用的语义分割基准，我们用1464幅训练图像训练SSN，并对1449幅验证图像进行验证。图8(a)为不同技术的ASA评分。我们不分析这个数据集上的边界得分，因为GT语义边界被一个忽略标签扩展了。ASA评分表明，SSNdeep的性能优于其他技术。我们还对该数据集上的bsds训练模型进行了评估，发现其精度仅略有下降(图8(a)中的SSNdeep-BSDS)。这说明了SSN对不同数据集的通用性和鲁棒性。图7是一个可视化的例子，补充了更多的内容。

![ss](/img/2019-07-11-27.png)

## 6. 总结

我们提出一种新的超像素采样网络(SSN)，它利用通过端到端训练学习到的深层特征来估计特定于任务的超像素。据我们所知，这是第一种可以从头到尾训练的深度超像素预测技术。实验表明，SSN的性能始终优于最先进的超像素技术，同时也更快。将SSN集成到语义分割网络[13]中，还可以提高性能，显示SSN在下游计算机视觉任务中的有效性。SSN速度快，易于实现，可以方便地集成到其他深度网络中，具有良好的经验性能。

SSN解决了将超像素并入深度网络的主要障碍之一，即现有超像素算法的不可微性。在深层网络中使用超像素有几个优点。超像素可以降低计算复杂度，特别是在处理高分辨率图像时。超像素还可用于执行分割常数假设，并有助于远程信息传播[13]。我们相信这项工作为在深层网络中利用超像素开辟了新的途径，也激发了使用超像素的新的深度学习技术。

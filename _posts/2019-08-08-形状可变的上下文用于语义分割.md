---

layout:     post
title:      形状可变的上下文用于分割
subtitle:   Semantic Correlation Promoted Shape-Variant Context for Segmentation
date:       2019-08-08
author:     Nick
header-img: img/博客背景.jpg
catalog: true
tags:
    - 论文阅读
---

## 摘要

上下文是语义分割的基础。**由于物体形状的多样性及其在各种场景图像中的复杂布局，不同物体的空间尺度和上下文形状有很大的变化。**因此，从预定义的固定区域聚合各种上下文信息是无效的。在这项工作中，我们提出为每个像素生成一个尺度和形状变化的语义掩码来限制其上下文区域。为此，我们首先提出了一种新颖的成对卷积算法来推导出对的语义相关关系，并在此基础上生成形状掩码。利用上下文区域的推断空间范围，我们**提出了一种形状变化卷积，其中接受域由形状掩模控制**，形状掩模随输入的出现而变化。这样，所提出的网络从像素的语义相关区域而不是预定义的固定区域聚合像素的上下文信息。此外，本文还提出了一种标签去噪模型，以减少低噪声特征引起的错误预测。在没有任何附加条件的情况下，提出的分割网络在六个公共分割数据集上实现了SOTA。

## 1. 简介

语义分割或场景解析旨在将场景图像中的每个像素分类为预定类别之一（例如，人，汽车等）。它一直是人工智能的关键，可以应用于许多实践应用，如自动停车系统。最近深度神经网络的成功极大地提高了语义分割的性能[9,43,75,11]。大多数现有的分割网络基于在ImageNet [58]上预训练的卷积神经网络（CNN）[37,63,64,26,28]，其中CNN被用作局部特征提取器。**为了实现强大的语义分割，高级上下文是必要的**。上下文提供了对象形成的周围环境，这有助于更好地区分对象。

![imfg](/img/2019-08-08-1.png)

*图1.大多数现有方法使用预定义窗口（例如，第二图像中的像素A的红色矩形区域）来模拟依赖于空间的上下文，其可能不提供特定的上下文信息并因此削弱语义形状布局。在这项工作中，我们建议聚合来自**语义依赖区域的上下文信息**，**而不是空间依赖区域**。*

然而，由于场景图像中各种形状（包括轮廓，尺度等）和对象的复杂布局，**在预定义的固定区域内聚合的共同上下文削弱了语义形状布局并且可能带来不必要的无关信息**。例如，在图1中，像素A（湖）和像素B（火车）的上下文应该是不同的，但是预先接收的接收领域用于收集它们的上下文很大程度上重叠，这降低了它们的辨别力。同时，预先定义的周围区域（第二图像中的矩形区域）中的所有信息并非对其最终解析有益。在语义相关区域中收集的信息对于识别对象更有帮助，而在不相关区域中的信息虽然在空间上接近，但可能导致解析错误，因此应该被抑制或甚至被忽略。对于图1中的像素A，属于湖泊及其岸边的像素的信息是语义相关的，可能比预定义的固定窗口中的其他像素的信息更有益。对于像素B，理想的上下文形状将与火车和铁路轨道对齐。此外，统一整合平滑的全局信息会降低位置身份和局部判别特征[69]。因此，为了更好地场景解析，应该定制不同形状的语义一致上下文。大多数现有方法倾向于在固定的矩形区域[9,18,73,71]或全局区域[72,74,30]中模拟统计平均表示。在这项工作中，通过考虑对象的语义相关性和形状布局，我们提出了一种形状可变上下文模型，用于根据输入图像的外观推断出来自其语义相关区域的每个像素的周围信息。

为此，我们首先建议通过新的**成对卷积后跟高斯映射函数来学习目标像素与其他像素之间的关系**。学习的网络对于具有更强语义相关性的两个像素产生更高的值，而对于更弱的相关性产生更低的值。因此，所提出的网络将**生成指示每个像素的语义相关区域的形状掩码**。利用形状掩码指定所需感受野的大小和形状，我们**进一步提出了一种形状可变卷积来聚合来自语义依赖区域的上下文**。形状变量卷积由一组可学习的位置不变卷积参数和位置可变形状掩模指定。因此，参数是输入图像的语义相关区域的因变量，其随着对象的不同形状和比例而变化。此外，由于形状变量上下文是隐式缩放变量，我们不仅可以在单个层中模拟多形状而且可以模拟多尺度信息，而不是并行[9,75,71]或堆叠[73,18]多个-layers。从宏观角度来看，所提出的方法通过学习特征的语义和空间关系并确定信息传递或抑制来帮助控制网络内的信息流。

所提出的尺度和形状可变上下文模型增强了高级特征的辨别力。较高级别的特征比较低级别的特征对噪声更具鲁棒性，而且空间位置灵敏度较低。因此，许多分割网络也聚合低级特征以提高分割的位置准确性[51,11,18,25]。**然而，聚合低级特征虽然有助于恢复空间信息，但可能会带来一些有争议的噪声敏感信息，导致某些像素的错误分类。因此，我们提出了一种模型，该模型利用较高级别的特征来在聚合它们之前衰减低级特征的噪声信息，即信号去噪。通过这种方式，网络可以通过减轻其问题来更好地利用低级特征的优点。**

总之，本文做出以下**贡献**：**1）我们提出了一种新的成对卷积来推断两个像素的语义相关性，并在此基础上为每个像素生成语义相关区域; 2）我们提出了在语义相关区域内聚合的形状变异上下文来模拟上下文的不同形状和尺度，极大地增强了网络的建模能力; 3）我们提出了一种标记去噪模型，以减少噪声低级特征引起的标记错误; 4）我们在六个公共语义分割数据集上一致地实现了新的最先进的性能。**

## 2. 相关工作

最近，深度神经网络在计算机视觉方面取得了巨大成功[26,23,22,47,49,24,50,65]。基于完全卷积网络（FCN）[51]，其中原始CNN中的完全连接的层被转换为卷积层，许多方法，例如，[9,21,55,32,48,76,5， [61]，提高了语义分割的性能。

上下文特征建模在场景解析中起着重要作用。 [52]表明全局空间信息有助于强化特征的一致性。DeepLab [9]提出了一种不稳定的空间金字塔池（ASPP）来聚合具有不同膨胀率的并行分支的多尺度图像表示。DilatedNet [73]在得分图之后附加几个扩张的卷积层以执行多尺度上下文聚合。DAG-RNN [62]和Byeon [6]提出通过递归神经网络模拟远程上下文。缩小[53]提出了一种前馈架构来提取分层缩小特征。CRF-RNN [77]使用循环层对密集CRF [36]及其分段网络进行联合端到端训练。Piecewise [44]制定基于CNN的成对势能函数来捕获补丁 - 补丁上下文并为补丁 - 背景上下文设计图像金字塔输入。PSPNet [75]引入了金字塔空间池（PSP）来执行基于区域的不同全局信息聚合。最近，CCL [18]提出了一种上下文对比的本地模型，以并行收集本地及其周围的信息。EncNet [74]将语义上下文编码为网络和压力类依赖的特征映射。与以前的方法不同，在这项工作中，我们尝试从语义更接近的区域聚合上下文信息，即使在空间临近区域也抑制无关信息。我们提出了一种形状自适应卷积层来学习各种形状的上下文，其形状由输入图像的对象形状，比例及其周围支撑决定。所提出的方法不仅旨在保留位置标识和布局信息，还旨在建立训练图像中所示的有效语义相关性。

![imfg](/img/2019-08-08-2.png)

*图2. 我们提出了一种新颖的语义相关依赖形状可变上下文，它可以增强语义相关特征（洋红色），同时抑制其他特征（白色）。*

标签变体是语义分割中的另一个挑战性问题。PSPNet [75]观察了混淆类别，并证明PSPNet可以比FCN更好地解决混淆标签[51]。我们提出了一种可学习的标记去噪（LD）模型，通过利用鲁棒的更高级特征来减弱低级特征中的噪声来解决混淆标签的问题。

## 3. 方法

### 3.1 语义相关依赖的上下文

**语义分割需要同时处理对象识别和定位，因此应该在大区域之间建立密集的特征连接以及保留位置标识**。同时，由于场景图像中物体的形状多样，布局复杂，不同物体的物体尺度和形状应该有很大的变化。

许多现有的上下文建模方法倾向于在所有位置上使用固定大小的矩形窗口来聚集周围信息，这削弱了位置标识并且可能无法有效地表示场景图像中的对象的不同形状和比例。与以前的工作不同，我们提出根据对象的形状及其支持对象的背景，更理想的上下文区域应该是形状可变。例如，对于属于图2中的列车的像素，更有益的上下文应该是沿铁路轨道（品红色）的周围信息，其在语义上比在空间中更接近。总之，对于不同的像素位置，应该从支持该像素的正确类的存在的语义相关区域收集周围信息。因此，**在这项工作中，我们提出了一个依赖于语义相关的形状可变上下文（SVC）来模拟具有位置标识的不同形状/尺度上下文。****在SVC中，上下文聚合由语义相关掩码控制，**指定应在何种程度上收集信息的位置。**利用语义掩码，语义相关区域中的特征被提升，并且其他不相关区域中的特征被抑制**。因此，用于解析每个像素的更好的上下文信息被聚合在支持对象的正确类的存在的特定形状区域内。

![imfg](/img/2019-08-08-3.png)

*图3. 形状掩模由配对卷积和高斯映射函数φ推断，其设计用于学习目标像素与形状掩模内的其他像素之间的语义相关性。这里我们展示了目标像素（暗）的11×11掩模中的4个值的示例，其中4个掩模值由相同颜色的4个滤波器生成。*

#### 3.1.1 学习语义关联

接下来，我们将讨论如何学习语义相关性，即如何生成语义形状掩码。形状掩模中的每个值表示对应像素与目标像素（掩模的中心像素）的相关性。因此，需要学习每个像素与目标像素的语义关系并将其注入到形状掩模中的对应位置。为此，我们引入了一个成对卷积，如图3所示，其中**使用一对具有特定相对位置的`3x3`局部卷积来学习相应像素与目标像素的语义和空间相关性**（中心暗像素）在图3)中。在成对卷积的每个滤波器中，存在用于目标像素的中心卷积和另一个卷积，其位置对应于对应像素的形状掩模中的位置。我们观察并因此假设**属于同一对象及其上下文的像素的特征外观将显示强相关性**，因为它们经常在训练图像中共存。因此，通过从训练图像学习卷积参数，可以使属于同一对象及其上下文的两个像素的两个卷积输出的差异最小化。

![imfg](/img/2019-08-08-4.png)

其中，*表示卷积操作，D表示目标像素（i，j）和相应像素（i-m, j-n）经过局部3x3卷积输出后的差异。Θ 表示两个不同的卷积操作（keras中的local_conv2d）。最后通过高斯函数得到掩模对应位置的值。

![imfg](/img/2019-08-08-5.png)

其中，![imfg](/img/2019-08-08-6.png)，较小的差异会产生较高的语义相关值。M是像素（i，j）的语义形状掩码中位置（m，n）处的掩码值。注意，结果对σ不敏感，因为学习了两个卷积的参数。我们在实验中使用σ = 3 。

#### 3.1.2 形状可变上下文

形状可变上下文的目标是为每个像素定制所需的上下文形状/尺度，而不是简单的平滑上下文信息。为了实现这一点，我们进一步提出了形状可变卷积（SV Conv）以自适应地收集周围信息。形状变量卷积的参数由位置不变的可学习卷积参数和由所提出的成对卷积推断的语义形状掩码组成。形状掩模用于根据语义相关性控制每个位置的卷积过程的感受野。这种形状掩模将卷积核切割成不同的形状/比例，并导致形状变化的卷积操作。通过这种方式，所提出的方法极大地增强了不同形状上下文的网络建模能力。

![imfg](/img/2019-08-08-7.png)

*图4.依赖于语义相关的形状可变上下文根据语义相关性聚合周围信息，从而定制有效的上下文区域。它通过决定要传递或抑制的信息来帮助控制网络中的信息流。*

提出的形状可变上下文如图4.所示。有两个分支，旁路用于学习语义相关性，然后将其输出输入到形状变量卷积（SV Conv）以提供语义形状掩码。详细地，侧分支采用成对卷积来从预训练的CNN中学习局部特征F，并计算每个像素与以该像素为中心的KxK大小的内核中的每个其他像素的相关性，输出通道的数量是S=KxK，其中KxK是建议的形状变量卷积的内核大小。**语义形状掩模用于加权主分支的正常可学习卷积**（F滤波器）.

标准卷积操作是位置不变的，并且在训练之后不随测试图像而变化。因此，它不能为输入图像的不同对象定制不同形状/尺度的上下文信息。所提出的SV Conv包括可学习的位置不变卷积和从输入图像推断的位置变量语义形状掩模。

### 3.2 标记去噪

所提出的**形状可变上下文聚合来自特定语义相关区域的信息，这有助于减轻上下文和外部上下文标记错误**。为了获得精细的空间信息，CNN中间层的低级特征在编码器 - 解码器架构[51,11,18,25]中很重要，因为它们包含有关这些对象在哪里的更多信息[21,51]。但是这些**低级特征还会带来有争议的噪声信息，导致出现上下文错误。**相反，高级特征（例如，该工作中的形状变化上下文，虽然对空间位置不太敏感）对噪声更鲁棒并且更加了解场景图像中存在哪些类别。**为了更好地将“what”和“where”结合起来，我们在这项工作中提出了一种标记去噪（LD）模型，它可以在提取时降低噪声信息，相当于使用高级特征指导（降噪）低级特征。**

具体做法是：

**首先对于最低级尺度的特征图，生成其得分图S，并进行softmax，然后执行最大池化，得到与类别数相等的几个数值，每个类别对应一个数值，每个数值表示图片中存在该类别的概率。**

![img](/img/2019-08-08-08.png)

**然后将每个类别的概率值通过惩罚阈值T、可学习的参数∆ 以及RELU，得到乘法P；**

**还是没有弄明白惩罚系数P是一个数值还是一个矩阵。**

![2019-08-08-9](/img/2019-08-08-9.png)

**进而惩罚P作为连接相邻尺度的桥梁，逐步逐步得到最高尺度的得分图也就是最终结果。**

![2019-08-08-10](/img/2019-08-08-10.png)

对于来自低级特征的跳过层，输入图像中不存在的类别的得分被衰减，并且现有类别的得分被保留并补充到用于定位增强的得分图。由于该机制包括在端到端训练过程中，因此在训练期间考虑较少的噪声分数，并且可以保存用于训练这种噪声信息的梯度以用于诸如定位之类的其他事物。

![2019-08-08-11](/img/2019-08-08-11.png)

## 4. 实验

我们评估了六种公共基准，COCO-Stuff，SIFT-Flow，CamVid，PASCAL-PersonPart，PASCAL-Context和Cityscapes。我们使用在ImageNet [58]上预训练的ResNet101 [26]作为微调和FCN-4作为骨干框架的基本模型。在训练期间，建议的网络使用标准SGD进行端到端训练，批量大小为8，固定动量为0.9，重量衰减为0.0005。在训练中使用数据增强，如随机翻转，0.8到1.2之间的随机大小调整和平均减法。受[9]的启发，我们使用“poly”学习速率并将初始学习速率设置为5x10-3用于新层的初始化参数，将10-4设置为预训练层的初始化参数，功率设置为0.9。批量标准化[31]用于新添加的层以加速培训过程。性能通过标准像素精度（pixel acc. ），平均类精度（mean acc. ）和平均交叉联合（mIoU）来评估。有关数学定义，请参阅[51]。

为了在单个层中对不同的语义形状进行建模，由于对象的形状/比例变化剧烈，因此需要更大的内核。但非常大的内核是资源密集型的，很难收敛。为了解决这个问题，我们修改了Eq（4）提出的SVC类似于深度可分离卷积[13]。方程式的简化计算允许我们使用大内核大小来模拟空间空间中的各种形状，然后进行逐点卷积以学习跨通道相关性。

![img](/img/2019-08-08-12.png)

![2019-08-08-13](/img/2019-08-08-13.png)

![2019-08-08-14](/img/2019-08-08-14.png)

![2019-08-08-15](/img/2019-08-08-15.png)

---
layout:     post
title:      VGGNet阅读笔记及代码理解
subtitle:   Very Deep Convolutional Networks for Large-Scale Image Recognition(Published as a conference paper at ICLR 2015)
date:       2019-05-15
author:     Nick
header-img: img/博客背景.jpg
catalog: true
tags:
    - 论文阅读
---

## 摘要：

我们的主要贡献是使用具有非常小尺寸的卷积核 (`3x3`) 的体系结构对深度网络进行深入评估，这表明通过将深度推到16-19个权重层可以实现对现有技术配置的显着改进。

## 1. 简介

**第一段：**寒暄一下，说一下前人工作和领域发展，ImageNet开源数据集和GPU。

**第二段：**稍微过一下发展历程和发展路线，比如多尺度啦，紧接着简略地说他们解决的深度问题，由于全部使用`3x3`卷积。

**第三段：**说一下自己网络的优点，不仅在imagenet数据集上效果好了，也适用于其他数据集，并且甚至可以使用他们预训练的网络参数进行特征提取进而输入到SVM分类，效果也不错。

**第四段：**文章剩余部分章节安排，第二部分描述网络配置，第三部分描述训练和验证细节，第四部分就是在imagenet上的实验结果对比，第五部分总结，为了完整性，附录还在其他任务和其他数据集上做了实验。

## 2. 网络配置

### 2.1 网络架构

| 固定大小的输入 |     卷积     |     卷积      | 非线性 |  maxpooling   |             FC             |
| :------------: | :----------: | :-----------: | :----: | :-----------: | :------------------------: |
|    224 x224    | 3x3(padding) | 1x1(线性变换) |  ReLU  | kernel=2, s=2 | 4096->4096->1000 (softmax) |

### 2.2 配置

![网络配置](/img/2019-05-15-1.png)

![参数量对比](/img/2019-05-15-2.png)

### 2.3 讨论

相比于之前的一些网络，我们采用3x3的小卷积核，很明显，两个堆叠的3x3卷积相当于一个5x5的卷积核的感受野，三个3x3的卷积核堆叠相当于一个7x7的卷积核的感受野。但是我们的**非线性层变多**了，更具有识别力，同时**参数量更少**了，可以看作给7x7卷积引入了正则化。

1x1卷积和他后面跟的非线性层可以增加网络的的表示能力。

## 3. 分类框架

### 3.1 训练：

|        优化器        | batch | 动量 |   正则化   |     学习率     | 迭代次数 |               参数初始化               |          数据扩充          |
| :------------------: | ----- | ---- | :--------: | :------------: | :------: | :------------------------------------: | :------------------------: |
| 带动量小批量梯度下降 | 256   | 0.9  | L2+dropout | 0.01 (不降/10) |    74    | A随机，B-E用A结果初始化，A没有的层随机 | 裁剪、缩放、平移、颜色都懂 |

### 3.2 测试

数据扩充：水平翻转，多次裁剪测试

### 3.3 工具

caffe 多GPU训练

## 4. 分类实验

### 4.1 数据集

ImageNet简介

### 4.2 单尺度评估

A网络上加了LRN，发现没有提升，后面的结构就都没用；

网络深度达到E，也就是19层就达到饱和，可能更大的数据集增加深度会有提升；

D比C好，所以1x1虽然能增加非线性，但是3x3捕获上下文特征也很重要；

### 4.3 多尺度评估

多尺度测试，结果取平均，又是一个表。

### 4.4 与现有技术比较

